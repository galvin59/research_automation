
# ğŸ§  Outil automatisÃ© de recherche documentaire (IA)

Ce projet permet de lancer une **recherche documentaire automatisÃ©e** sur nâ€™importe quel sujet, en combinant des outils dâ€™intelligence artificielle et des sources acadÃ©miques. Il produit en sortie une **synthÃ¨se structurÃ©e** et un **rapport HTML final**.

---

## ğŸ—‚ Structure du projet

```
research_automation/
â”œâ”€â”€ main.py                       # Script principal (optionnel)
â”œâ”€â”€ config.yaml                   # Configuration gÃ©nÃ©rale (API, sources, topic, etc.)
â”œâ”€â”€ autres_liens.csv              # Liens Perplexity exportÃ©s manuellement (un lien par ligne)
â”œâ”€â”€ questions.json                # Questions gÃ©nÃ©rÃ©es automatiquement Ã  partir du topic
â”œâ”€â”€ sources_combinees_par_question.csv  # RÃ©sultat consolidÃ© des sources collectÃ©es
â”œâ”€â”€ requirements.txt              # DÃ©pendances Python
â”œâ”€â”€ .env                          # ClÃ©s API (CORE)
â””â”€â”€ src/
    â”œâ”€â”€ generer_questions.py      # Ã‰tape 0 : GÃ©nÃ©ration automatique des questions
    â”œâ”€â”€ collecte_sources.py       # Ã‰tape 1 : Collecte des sources depuis APIs et autres_liens.csv
    â”œâ”€â”€ generer_synthese.py       # Ã‰tape 2 : GÃ©nÃ©ration de synthÃ¨se par question
    â””â”€â”€ generer_rapport.py        # Ã‰tape 3 : Consolidation en rapport HTML
```

---

## âš™ï¸ PrÃ©requis

- Python 3.10+
- Un fichier `.env` contenant la variable `CORE_API_KEY` (voir `.env.example`)
- Installation des dÃ©pendances :

```bash
pip install -r requirements.txt
```

---

## ğŸ§© Ã‰tapes du pipeline de recherche

### ğŸ” Ã‰tape 0 â€” GÃ©nÃ©rer les questions Ã  partir du topic

```bash
python src/generer_questions.py
```

- Ã€ partir du champ `topic` dans `config.yaml`, gÃ©nÃ¨re des questions pertinentes dans `questions.json`.

---

### ğŸ” Ã‰tape 1 â€” Collecte automatique de sources

```bash
python src/collecte_sources.py
```

- Utilise les APIs **Semantic Scholar**, **OpenAlex**, et **CORE** 
- Ajoute les liens contenus dans `autres_liens.csv` (export manuel depuis Perplexity ou autre outil non api-sÃ©, un lien par ligne).
- RÃ©sultat dÃ©dupliquÃ© dans `sources_combinees_par_question.csv`.

---

### ğŸ§  Ã‰tape 2 â€” GÃ©nÃ©rer une synthÃ¨se par question

```bash
python src/generer_synthese.py
```

- Utilise soit OpenAI (si configurÃ©), soit un modÃ¨le local (par ex. via **LM Studio**) en HTTP pour rÃ©sumer les sources par question.

ğŸ”§ Pour LM Studio :
- Activer un serveur local (ex: `localhost:1234`) avec un modÃ¨le LLM compatible ChatML (Mistral, LLaMA, etc.).
- Indiquer l'URL dans `config.yaml` (champ `llm_endpoint`).

---

### ğŸ§¾ Ã‰tape 3 â€” GÃ©nÃ©rer un rapport HTML complet

```bash
python src/generer_rapport.py
```

- Regroupe toutes les synthÃ¨ses dans un fichier HTML lisible (`rapport_final.html`).
- Le rapport peut Ãªtre enrichi automatiquement avec table des matiÃ¨res, titres, et sÃ©parateurs.

---

## ğŸ§ª Exemple de fichier `config.yaml`

```yaml
topic: "Artificial Intelligence and environmental impact"
autres_liens_csv: "autres_liens.csv"
result_limit: 10
sources:
  semantic_scholar: true
  openalex: true
  core: true
llm:
  provider: "openai"  # ou "local"
  openai_api_key: "sk-..."  # requis si provider = openai
  llm_endpoint: "http://localhost:1234/v1/chat/completions"  # si provider = local
```

---

## ğŸ” Exemple de `.env`

```
CORE_API_KEY=xxxxxxxxxxxxxxxxxxxxxxxx
```

---

## âœ¨ RÃ©sultat final

Le rapport est gÃ©nÃ©rÃ© automatiquement en HTML avec une synthÃ¨se par question. Il peut Ãªtre ouvert directement dans un navigateur.

---

## ğŸ“Œ Ã€ propos

Ce projet est conÃ§u pour faciliter les recherches documentaires rigoureuses Ã  lâ€™aide de lâ€™IA. Il peut sâ€™adapter Ã  tout sujet : environnement, droit, mÃ©decine, sociologie, etc.

